@article{article,
  author  = {Gouthaman KG}, 
  title   = {The title of the work},
  journal = {The name of the journal},
  year    = 1993,
  number  = 2,
  pages   = {201-213},
  month   = 7,
  note    = {An optional note}, 
  volume  = 4
}

@inbook{inbook,
  author       = {Gouthaman KG}, 
  title        = {The title of the work},
  chapter      = 8,
  pages        = {201-213},
  publisher    = {The name of the publisher},
  year         = 1993,
  volume       = 4,
  series       = 5,
  address      = {The address of the publisher},
  edition      = 3,
  month        = 7,
  note         = {An optional note}
}

@book{book,
  author    = {Gouthaman KG}, 
  title     = {The title of the work},
  publisher = {The name of the publisher},
  year      = 1993,
  volume    = 4,
  series    = 10,
  address   = {The address},
  edition   = 3,
  month     = 7,
  note      = {An optional note},
  isbn      = {3257227892}
}

@article{10.1145/3054912,
author = {Hussein, Ahmed and Gaber, Mohamed Medhat and Elyan, Eyad and Jayne, Chrisina},
title = {Imitation Learning: A Survey of Learning Methods},
year = {2017},
issue_date = {June 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3054912},
doi = {10.1145/3054912},
abstract = {Imitation learning techniques aim to mimic human behavior in a given task. An agent (a learning machine) is trained to perform a task from demonstrations by learning a mapping between observations and actions. The idea of teaching by imitation has been around for many years; however, the field is gaining attention recently due to advances in computing and sensing as well as rising demand for intelligent applications. The paradigm of learning by imitation is gaining popularity because it facilitates teaching complex tasks with minimal expert knowledge of the tasks. Generic imitation learning methods could potentially reduce the problem of teaching a task to that of providing demonstrations, without the need for explicit programming or designing reward functions specific to the task. Modern sensors are able to collect and transmit high volumes of data rapidly, and processors with high computational power allow fast processing that maps the sensory data to actions in a timely manner. This opens the door for many potential AI applications that require real-time perception and reaction such as humanoid robots, self-driving vehicles, human computer interaction, and computer games, to name a few. However, specialized algorithms are needed to effectively and robustly learn models as learning by imitation poses its own set of challenges. In this article, we survey imitation learning methods and present design options in different steps of the learning process. We introduce a background and motivation for the field as well as highlight challenges specific to the imitation problem. Methods for designing and evaluating imitation learning tasks are categorized and reviewed. Special attention is given to learning methods in robotics and games as these domains are the most popular in the literature and provide a wide array of problems and methodologies. We extensively discuss combining imitation learning approaches using different sources and methods, as well as incorporating other motion learning methods to enhance imitation. We also discuss the potential impact on industry, present major applications, and highlight current and future research directions.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {21},
numpages = {35},
keywords = {Imitation learning, learning from demonstrations, intelligent agents, robotics, deep learning, learning from experience, self-improvement, feature representations, reinforcement learning}
}

@article{pomerleau1991efficient,
	title={Efficient training of artificial neural networks for autonomous navigation},
	author={Pomerleau, Dean A},
	journal={Neural computation},
	volume={3},
	number={1},
	pages={88--97},
	year={1991},
	publisher={MIT Press}
}

@misc{ho2016generative,
      title={Generative Adversarial Imitation Learning}, 
      author={Jonathan Ho and Stefano Ermon},
      year={2016},
      eprint={1606.03476},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{li2017infogail,
      title={InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations}, 
      author={Yunzhu Li and Jiaming Song and Stefano Ermon},
      year={2017},
      eprint={1703.08840},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{10.5555/1162264,
author = {Bishop, Christopher M.},
title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
year = {2006},
isbn = {0387310738},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}

@inproceedings{ramachandran2007bayesian,
	title={Bayesian Inverse Reinforcement Learning.},
	author={Ramachandran, Deepak and r, Eyal},
	booktitle={IJCAI},
	volume={7},
	pages={2586--2591},
	year={2007}
}

 @misc{hussein_crowe_petrik_begum_2020,
    title={Robust Maximum Entropy Behavior Cloning},
    url={http://www.robot-learning.ml/2020/files/D1.pdf},
    journal={3rd Robot Learning Workshop: Grounding Machine Learning Development in the Real World},
    publisher={NeurIPS},
    author={Hussein, Mostafa and Crowe, Brendan and Petrik, Marek and Begum, Momotaz},
    year={2020},
    month={Dec}
}

@ARTICLE{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@misc{brockman2016openai,
      title={OpenAI Gym}, 
      author={Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
      year={2016},
      eprint={1606.01540},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}